{"version":3,"sources":["BufferedTokenStream.js","../src/BufferedTokenStream.ts"],"names":["__decorate","decorators","target","key","desc","c","arguments","length","r","Object","getOwnPropertyDescriptor","d","Reflect","decorate","i","defineProperty","__param","paramIndex","decorator","exports","value","assert","require","CommonToken_1","Interval_1","Lexer_1","Decorators_1","Token_1","BufferedTokenStream","tokenSource","tokens","p","fetchedEOF","Error","_tokenSource","marker","index","lazyInit","adjustSeekIndex","skipEofCheck","LA","Token","EOF","sync","n","fetched","fetch","t","nextToken","isWritableToken","tokenIndex","push","type","RangeError","start","stop","subset","Array","token","LT","INVALID_TYPE","k","undefined","result","tryLT","tryLB","setup","types","slice","Set","add","typesSet","filteredTokens","filter","has","channel","size","nextOnChannel","nextTokenOnChannel","Lexer","DEFAULT_TOKEN_CHANNEL","to","from","filterForChannel","prevOnChannel","previousTokenOnChannel","hidden","interval","Interval","of","sourceInterval","a","b","fill","buf","text","toString","isToken","getText","blockSize","CommonToken","sourceName","NotNull","prototype","Override"],"mappings":"AAAA;ACAA;;;;;;;;;;;;;ADKA,IAAIA,UAAU,GAAI,UAAQ,SAAKA,UAAd,IAA6B,UAAUC,UAAV,EAAsBC,MAAtB,EAA8BC,GAA9B,EAAmCC,IAAnC,EAAyC;AACnF,MAAIC,CAAC,GAAGC,SAAS,CAACC,MAAlB;AAAA,MAA0BC,CAAC,GAAGH,CAAC,GAAG,CAAJ,GAAQH,MAAR,GAAiBE,IAAI,KAAK,IAAT,GAAgBA,IAAI,GAAGK,MAAM,CAACC,wBAAP,CAAgCR,MAAhC,EAAwCC,GAAxC,CAAvB,GAAsEC,IAArH;AAAA,MAA2HO,CAA3H;AACA,MAAI,QAAOC,OAAP,0DAAOA,OAAP,OAAmB,QAAnB,IAA+B,OAAOA,OAAO,CAACC,QAAf,KAA4B,UAA/D,EAA2EL,CAAC,GAAGI,OAAO,CAACC,QAAR,CAAiBZ,UAAjB,EAA6BC,MAA7B,EAAqCC,GAArC,EAA0CC,IAA1C,CAAJ,CAA3E,KACK,KAAK,IAAIU,CAAC,GAAGb,UAAU,CAACM,MAAX,GAAoB,CAAjC,EAAoCO,CAAC,IAAI,CAAzC,EAA4CA,CAAC,EAA7C;AAAiD,QAAIH,CAAC,GAAGV,UAAU,CAACa,CAAD,CAAlB,EAAuBN,CAAC,GAAG,CAACH,CAAC,GAAG,CAAJ,GAAQM,CAAC,CAACH,CAAD,CAAT,GAAeH,CAAC,GAAG,CAAJ,GAAQM,CAAC,CAACT,MAAD,EAASC,GAAT,EAAcK,CAAd,CAAT,GAA4BG,CAAC,CAACT,MAAD,EAASC,GAAT,CAA7C,KAA+DK,CAAnE;AAAxE;AACL,SAAOH,CAAC,GAAG,CAAJ,IAASG,CAAT,IAAcC,MAAM,CAACM,cAAP,CAAsBb,MAAtB,EAA8BC,GAA9B,EAAmCK,CAAnC,CAAd,EAAqDA,CAA5D;AACH,CALD;;AAMA,IAAIQ,OAAO,GAAI,UAAQ,SAAKA,OAAd,IAA0B,UAAUC,UAAV,EAAsBC,SAAtB,EAAiC;AACrE,SAAO,UAAUhB,MAAV,EAAkBC,GAAlB,EAAuB;AAAEe,IAAAA,SAAS,CAAChB,MAAD,EAASC,GAAT,EAAcc,UAAd,CAAT;AAAqC,GAArE;AACH,CAFD;;AAGAR,MAAM,CAACM,cAAP,CAAsBI,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C,E,CCTA;;AAEA,IAAAC,MAAA,GAAAC,OAAA,CAAA,QAAA,CAAA;;AACA,IAAAC,aAAA,GAAAD,OAAA,CAAA,eAAA,CAAA;;AACA,IAAAE,UAAA,GAAAF,OAAA,CAAA,iBAAA,CAAA;;AACA,IAAAG,OAAA,GAAAH,OAAA,CAAA,SAAA,CAAA;;AACA,IAAAI,YAAA,GAAAJ,OAAA,CAAA,cAAA,CAAA;;AAEA,IAAAK,OAAA,GAAAL,OAAA,CAAA,SAAA,CAAA;AAKA;;;;;;;;;;;;;AAWA,IAAaM,mBAAmB;AAAA;AAAA;AAwC/B,+BAAqBC,WAArB,EAA6C;AAAA;;AAjC7C;;;;;AAKU,SAAAC,MAAA,GAAkB,EAAlB;AAEV;;;;;;;;;;;;AAWU,SAAAC,CAAA,GAAY,CAAC,CAAb;AAEV;;;;;;;;;;;;AAWU,SAAAC,UAAA,GAAsB,KAAtB;;AAGT,QAAIH,WAAW,IAAI,IAAnB,EAAyB;AACxB,YAAM,IAAII,KAAJ,CAAU,4BAAV,CAAN;AACA;;AAED,SAAKC,YAAL,GAAoBL,WAApB;AACA;;AA9C8B;AAAA;AAAA,2BAmEpB;AACV,aAAO,CAAP;AACA;AArE8B;AAAA;AAAA,4BAwEhBM,MAxEgB,EAwEF,CAC5B;AACA;AA1E8B;AAAA;AAAA,yBA6EnBC,KA7EmB,EA6EN;AACxB,WAAKC,QAAL;AACA,WAAKN,CAAL,GAAS,KAAKO,eAAL,CAAqBF,KAArB,CAAT;AACA;AAhF8B;AAAA;AAAA,8BAwFjB;AACb,UAAIG,YAAJ;;AACA,UAAI,KAAKR,CAAL,IAAU,CAAd,EAAiB;AAChB,YAAI,KAAKC,UAAT,EAAqB;AACpB;AACA;AACAO,UAAAA,YAAY,GAAG,KAAKR,CAAL,GAAS,KAAKD,MAAL,CAAYvB,MAAZ,GAAqB,CAA7C;AACA,SAJD,MAIO;AACN;AACAgC,UAAAA,YAAY,GAAG,KAAKR,CAAL,GAAS,KAAKD,MAAL,CAAYvB,MAApC;AACA;AACD,OATD,MASO;AACN;AACAgC,QAAAA,YAAY,GAAG,KAAf;AACA;;AAED,UAAI,CAACA,YAAD,IAAiB,KAAKC,EAAL,CAAQ,CAAR,MAAeb,OAAA,CAAAc,KAAA,CAAMC,GAA1C,EAA+C;AAC9C,cAAM,IAAIT,KAAJ,CAAU,oBAAV,CAAN;AACA;;AAED,UAAI,KAAKU,IAAL,CAAU,KAAKZ,CAAL,GAAS,CAAnB,CAAJ,EAA2B;AAC1B,aAAKA,CAAL,GAAS,KAAKO,eAAL,CAAqB,KAAKP,CAAL,GAAS,CAA9B,CAAT;AACA;AACD;AAED;;;;;;;AAjH+B;AAAA;AAAA,yBAuHhBjB,CAvHgB,EAuHP;AACvBO,MAAAA,MAAM,CAACP,CAAC,IAAI,CAAN,CAAN;AACA,UAAI8B,CAAC,GAAW9B,CAAC,GAAG,KAAKgB,MAAL,CAAYvB,MAAhB,GAAyB,CAAzC,CAFuB,CAEqB;AAC5C;;AACA,UAAIqC,CAAC,GAAG,CAAR,EAAW;AACV,YAAIC,OAAO,GAAW,KAAKC,KAAL,CAAWF,CAAX,CAAtB;AACA,eAAOC,OAAO,IAAID,CAAlB;AACA;;AAED,aAAO,IAAP;AACA;AAED;;;;;AAnI+B;AAAA;AAAA,0BAuIfA,CAvIe,EAuIN;AACxB,UAAI,KAAKZ,UAAT,EAAqB;AACpB,eAAO,CAAP;AACA;;AAED,WAAK,IAAIlB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG8B,CAApB,EAAuB9B,CAAC,EAAxB,EAA4B;AAC3B,YAAIiC,CAAC,GAAU,KAAKlB,WAAL,CAAiBmB,SAAjB,EAAf;;AACA,YAAI,KAAKC,eAAL,CAAqBF,CAArB,CAAJ,EAA6B;AAC5BA,UAAAA,CAAC,CAACG,UAAF,GAAe,KAAKpB,MAAL,CAAYvB,MAA3B;AACA;;AAED,aAAKuB,MAAL,CAAYqB,IAAZ,CAAiBJ,CAAjB;;AACA,YAAIA,CAAC,CAACK,IAAF,KAAWzB,OAAA,CAAAc,KAAA,CAAMC,GAArB,EAA0B;AACzB,eAAKV,UAAL,GAAkB,IAAlB;AACA,iBAAOlB,CAAC,GAAG,CAAX;AACA;AACD;;AAED,aAAO8B,CAAP;AACA;AA1J8B;AAAA;AAAA,wBA6JpB9B,CA7JoB,EA6JX;AACnB,UAAIA,CAAC,GAAG,CAAJ,IAASA,CAAC,IAAI,KAAKgB,MAAL,CAAYvB,MAA9B,EAAsC;AACrC,cAAM,IAAI8C,UAAJ,CAAe,iBAAiBvC,CAAjB,GAAqB,mBAArB,IAA4C,KAAKgB,MAAL,CAAYvB,MAAZ,GAAqB,CAAjE,CAAf,CAAN;AACA;;AAED,aAAO,KAAKuB,MAAL,CAAYhB,CAAZ,CAAP;AACA;AAED;;AArK+B;AAAA;AAAA,6BAsKfwC,KAtKe,EAsKAC,IAtKA,EAsKY;AAC1C,UAAID,KAAK,GAAG,CAAR,IAAaC,IAAI,GAAG,CAAxB,EAA2B;AAC1B,eAAO,EAAP;AACA;;AAED,WAAKlB,QAAL;AACA,UAAImB,MAAM,GAAY,IAAIC,KAAJ,EAAtB;;AACA,UAAIF,IAAI,IAAI,KAAKzB,MAAL,CAAYvB,MAAxB,EAAgC;AAC/BgD,QAAAA,IAAI,GAAG,KAAKzB,MAAL,CAAYvB,MAAZ,GAAqB,CAA5B;AACA;;AAED,WAAK,IAAIO,CAAC,GAAGwC,KAAb,EAAoBxC,CAAC,IAAIyC,IAAzB,EAA+BzC,CAAC,EAAhC,EAAoC;AACnC,YAAIiC,CAAC,GAAU,KAAKjB,MAAL,CAAYhB,CAAZ,CAAf;;AACA,YAAIiC,CAAC,CAACK,IAAF,KAAWzB,OAAA,CAAAc,KAAA,CAAMC,GAArB,EAA0B;AACzB;AACA;;AAEDc,QAAAA,MAAM,CAACL,IAAP,CAAYJ,CAAZ;AACA;;AAED,aAAOS,MAAP;AACA;AA3L8B;AAAA;AAAA,uBA8LrB1C,CA9LqB,EA8LZ;AAClB,UAAI4C,KAAK,GAAG,KAAKC,EAAL,CAAQ7C,CAAR,CAAZ;;AACA,UAAI,CAAC4C,KAAL,EAAY;AACX,eAAO/B,OAAA,CAAAc,KAAA,CAAMmB,YAAb;AACA;;AAED,aAAOF,KAAK,CAACN,IAAb;AACA;AArM8B;AAAA;AAAA,0BAuMfS,CAvMe,EAuMN;AACxB,UAAK,KAAK9B,CAAL,GAAS8B,CAAV,GAAe,CAAnB,EAAsB;AACrB,eAAOC,SAAP;AACA;;AAED,aAAO,KAAKhC,MAAL,CAAY,KAAKC,CAAL,GAAS8B,CAArB,CAAP;AACA;AA7M8B;AAAA;AAAA,uBAiNrBA,CAjNqB,EAiNZ;AAClB,UAAIE,MAAM,GAAG,KAAKC,KAAL,CAAWH,CAAX,CAAb;;AACA,UAAIE,MAAM,KAAKD,SAAf,EAA0B;AACzB,cAAM,IAAIT,UAAJ,CAAe,uCAAf,CAAN;AACA;;AAED,aAAOU,MAAP;AACA;AAxN8B;AAAA;AAAA,0BA0NlBF,CA1NkB,EA0NT;AACrB,WAAKxB,QAAL;;AACA,UAAIwB,CAAC,KAAK,CAAV,EAAa;AACZ,cAAM,IAAIR,UAAJ,CAAe,kCAAf,CAAN;AACA;;AAED,UAAIQ,CAAC,GAAG,CAAR,EAAW;AACV,eAAO,KAAKI,KAAL,CAAW,CAACJ,CAAZ,CAAP;AACA;;AAED,UAAI/C,CAAC,GAAW,KAAKiB,CAAL,GAAS8B,CAAT,GAAa,CAA7B;AACA,WAAKlB,IAAL,CAAU7B,CAAV;;AACA,UAAIA,CAAC,IAAI,KAAKgB,MAAL,CAAYvB,MAArB,EAA6B;AAC5B;AACA;AACA,eAAO,KAAKuB,MAAL,CAAY,KAAKA,MAAL,CAAYvB,MAAZ,GAAqB,CAAjC,CAAP;AACA,OAhBoB,CAkBrB;;;AACA,aAAO,KAAKuB,MAAL,CAAYhB,CAAZ,CAAP;AACA;AAED;;;;;;;;;;;;;;AAhP+B;AAAA;AAAA,oCA6PLA,CA7PK,EA6PI;AAClC,aAAOA,CAAP;AACA;AA/P8B;AAAA;AAAA,+BAiQb;AACjB,UAAI,KAAKiB,CAAL,KAAW,CAAC,CAAhB,EAAmB;AAClB,aAAKmC,KAAL;AACA;AACD;AArQ8B;AAAA;AAAA,4BAuQhB;AACd,WAAKvB,IAAL,CAAU,CAAV;AACA,WAAKZ,CAAL,GAAS,KAAKO,eAAL,CAAqB,CAArB,CAAT;AACA;AAUD;;;;;AApR+B;AAAA;AAAA,8BAwRdgB,KAxRc,EAwREC,IAxRF,EAwRiBY,KAxRjB,EAwR6C;AAC3E,WAAK9B,QAAL;;AAEA,UAAIiB,KAAK,KAAKQ,SAAd,EAAyB;AACxBzC,QAAAA,MAAM,CAACkC,IAAI,KAAKO,SAAT,IAAsBK,KAAK,KAAKL,SAAjC,CAAN;AACA,eAAO,KAAKhC,MAAZ;AACA,OAHD,MAGO,IAAIyB,IAAI,KAAKO,SAAb,EAAwB;AAC9BP,QAAAA,IAAI,GAAG,KAAKzB,MAAL,CAAYvB,MAAZ,GAAqB,CAA5B;AACA;;AAED,UAAI+C,KAAK,GAAG,CAAR,IAAaC,IAAI,IAAI,KAAKzB,MAAL,CAAYvB,MAAjC,IAA2CgD,IAAI,GAAG,CAAlD,IAAuDD,KAAK,IAAI,KAAKxB,MAAL,CAAYvB,MAAhF,EAAwF;AACvF,cAAM,IAAI8C,UAAJ,CAAe,WAAWC,KAAX,GAAmB,WAAnB,GAAiCC,IAAjC,GAAwC,aAAxC,IAAyD,KAAKzB,MAAL,CAAYvB,MAAZ,GAAqB,CAA9E,CAAf,CAAN;AACA;;AAED,UAAI+C,KAAK,GAAGC,IAAZ,EAAkB;AACjB,eAAO,EAAP;AACA;;AAED,UAAIY,KAAK,KAAKL,SAAd,EAAyB;AACxB,eAAO,KAAKhC,MAAL,CAAYsC,KAAZ,CAAkBd,KAAlB,EAAyBC,IAAI,GAAG,CAAhC,CAAP;AACA,OAFD,MAEO,IAAI,OAAOY,KAAP,KAAiB,QAArB,EAA+B;AACrCA,QAAAA,KAAK,GAAG,IAAIE,GAAJ,GAAkBC,GAAlB,CAAsBH,KAAtB,CAAR;AACA;;AAED,UAAII,QAAQ,GAAGJ,KAAf,CAxB2E,CA0B3E;;AACA,UAAIK,cAAc,GAAY,KAAK1C,MAAL,CAAYsC,KAAZ,CAAkBd,KAAlB,EAAyBC,IAAI,GAAG,CAAhC,CAA9B;AACAiB,MAAAA,cAAc,GAAGA,cAAc,CAACC,MAAf,CAAsB,UAACrD,KAAD;AAAA,eAAWmD,QAAQ,CAACG,GAAT,CAAatD,KAAK,CAACgC,IAAnB,CAAX;AAAA,OAAtB,CAAjB;AAEA,aAAOoB,cAAP;AACA;AAED;;;;;;;AAzT+B;AAAA;AAAA,uCA+TF1D,CA/TE,EA+TS6D,OA/TT,EA+TwB;AACtD,WAAKhC,IAAL,CAAU7B,CAAV;;AACA,UAAIA,CAAC,IAAI,KAAK8D,IAAd,EAAoB;AACnB,eAAO,KAAKA,IAAL,GAAY,CAAnB;AACA;;AAED,UAAIlB,KAAK,GAAU,KAAK5B,MAAL,CAAYhB,CAAZ,CAAnB;;AACA,aAAO4C,KAAK,CAACiB,OAAN,KAAkBA,OAAzB,EAAkC;AACjC,YAAIjB,KAAK,CAACN,IAAN,KAAezB,OAAA,CAAAc,KAAA,CAAMC,GAAzB,EAA8B;AAC7B,iBAAO5B,CAAP;AACA;;AAEDA,QAAAA,CAAC;AACD,aAAK6B,IAAL,CAAU7B,CAAV;AACA4C,QAAAA,KAAK,GAAG,KAAK5B,MAAL,CAAYhB,CAAZ,CAAR;AACA;;AAED,aAAOA,CAAP;AACA;AAED;;;;;;;;;;AAnV+B;AAAA;AAAA,2CA4VEA,CA5VF,EA4Va6D,OA5Vb,EA4V4B;AAC1D,WAAKhC,IAAL,CAAU7B,CAAV;;AACA,UAAIA,CAAC,IAAI,KAAK8D,IAAd,EAAoB;AACnB;AACA,eAAO,KAAKA,IAAL,GAAY,CAAnB;AACA;;AAED,aAAO9D,CAAC,IAAI,CAAZ,EAAe;AACd,YAAI4C,KAAK,GAAU,KAAK5B,MAAL,CAAYhB,CAAZ,CAAnB;;AACA,YAAI4C,KAAK,CAACN,IAAN,KAAezB,OAAA,CAAAc,KAAA,CAAMC,GAArB,IAA4BgB,KAAK,CAACiB,OAAN,KAAkBA,OAAlD,EAA2D;AAC1D,iBAAO7D,CAAP;AACA;;AAEDA,QAAAA,CAAC;AACD;;AAED,aAAOA,CAAP;AACA;AAED;;;;;AA/W+B;AAAA;AAAA,2CAmXDoC,UAnXC,EAmXuC;AAAA,UAApByB,OAAoB,uEAAF,CAAC,CAAC;AACrE,WAAKtC,QAAL;;AACA,UAAIa,UAAU,GAAG,CAAb,IAAkBA,UAAU,IAAI,KAAKpB,MAAL,CAAYvB,MAAhD,EAAwD;AACvD,cAAM,IAAI8C,UAAJ,CAAeH,UAAU,GAAG,aAAb,IAA8B,KAAKpB,MAAL,CAAYvB,MAAZ,GAAqB,CAAnD,CAAf,CAAN;AACA;;AAED,UAAIsE,aAAa,GAAW,KAAKC,kBAAL,CAAwB5B,UAAU,GAAG,CAArC,EAAwCzB,OAAA,CAAAsD,KAAA,CAAMC,qBAA9C,CAA5B;AACA,UAAIC,EAAJ;AACA,UAAIC,IAAI,GAAWhC,UAAU,GAAG,CAAhC,CARqE,CASrE;;AACA,UAAI2B,aAAa,KAAK,CAAC,CAAvB,EAA0B;AACzBI,QAAAA,EAAE,GAAG,KAAKL,IAAL,GAAY,CAAjB;AACA,OAFD,MAEO;AACNK,QAAAA,EAAE,GAAGJ,aAAL;AACA;;AAED,aAAO,KAAKM,gBAAL,CAAsBD,IAAtB,EAA4BD,EAA5B,EAAgCN,OAAhC,CAAP;AACA;AAED;;;;;AAtY+B;AAAA;AAAA,0CA0YFzB,UA1YE,EA0YsC;AAAA,UAApByB,OAAoB,uEAAF,CAAC,CAAC;AACpE,WAAKtC,QAAL;;AACA,UAAIa,UAAU,GAAG,CAAb,IAAkBA,UAAU,IAAI,KAAKpB,MAAL,CAAYvB,MAAhD,EAAwD;AACvD,cAAM,IAAI8C,UAAJ,CAAeH,UAAU,GAAG,aAAb,IAA8B,KAAKpB,MAAL,CAAYvB,MAAZ,GAAqB,CAAnD,CAAf,CAAN;AACA;;AAED,UAAI2C,UAAU,KAAK,CAAnB,EAAsB;AACrB;AACA,eAAO,EAAP;AACA;;AAED,UAAIkC,aAAa,GAAW,KAAKC,sBAAL,CAA4BnC,UAAU,GAAG,CAAzC,EAA4CzB,OAAA,CAAAsD,KAAA,CAAMC,qBAAlD,CAA5B;;AACA,UAAII,aAAa,KAAKlC,UAAU,GAAG,CAAnC,EAAsC;AACrC,eAAO,EAAP;AACA,OAdmE,CAgBpE;;;AACA,UAAIgC,IAAI,GAAWE,aAAa,GAAG,CAAnC;AACA,UAAIH,EAAE,GAAW/B,UAAU,GAAG,CAA9B;AAEA,aAAO,KAAKiC,gBAAL,CAAsBD,IAAtB,EAA4BD,EAA5B,EAAgCN,OAAhC,CAAP;AACA;AA/Z8B;AAAA;AAAA,qCAiaJO,IAjaI,EAiaUD,EAjaV,EAiasBN,OAjatB,EAiaqC;AACnE,UAAIW,MAAM,GAAY,IAAI7B,KAAJ,EAAtB;;AACA,WAAK,IAAI3C,CAAC,GAAGoE,IAAb,EAAmBpE,CAAC,IAAImE,EAAxB,EAA4BnE,CAAC,EAA7B,EAAiC;AAChC,YAAIiC,CAAC,GAAU,KAAKjB,MAAL,CAAYhB,CAAZ,CAAf;;AACA,YAAI6D,OAAO,KAAK,CAAC,CAAjB,EAAoB;AACnB,cAAI5B,CAAC,CAAC4B,OAAF,KAAclD,OAAA,CAAAsD,KAAA,CAAMC,qBAAxB,EAA+C;AAC9CM,YAAAA,MAAM,CAACnC,IAAP,CAAYJ,CAAZ;AACA;AACD,SAJD,MAIO;AACN,cAAIA,CAAC,CAAC4B,OAAF,KAAcA,OAAlB,EAA2B;AAC1BW,YAAAA,MAAM,CAACnC,IAAP,CAAYJ,CAAZ;AACA;AACD;AACD;;AAED,aAAOuC,MAAP;AACA;AAjb8B;AAAA;AAAA,4BA8bhBC,QA9bgB,EA8biB;AAC/C,UAAIA,QAAQ,KAAKzB,SAAjB,EAA4B;AAC3ByB,QAAAA,QAAQ,GAAG/D,UAAA,CAAAgE,QAAA,CAASC,EAAT,CAAY,CAAZ,EAAe,KAAKb,IAAL,GAAY,CAA3B,CAAX;AACA,OAFD,MAEO,IAAI,EAAEW,QAAQ,YAAY/D,UAAA,CAAAgE,QAAtB,CAAJ,EAAqC;AAC3C;AACAD,QAAAA,QAAQ,GAAGA,QAAQ,CAACG,cAApB;AACA;;AAED,UAAIpC,KAAK,GAAWiC,QAAQ,CAACI,CAA7B;AACA,UAAIpC,IAAI,GAAWgC,QAAQ,CAACK,CAA5B;;AACA,UAAItC,KAAK,GAAG,CAAR,IAAaC,IAAI,GAAG,CAAxB,EAA2B;AAC1B,eAAO,EAAP;AACA;;AAED,WAAKsC,IAAL;;AACA,UAAItC,IAAI,IAAI,KAAKzB,MAAL,CAAYvB,MAAxB,EAAgC;AAC/BgD,QAAAA,IAAI,GAAG,KAAKzB,MAAL,CAAYvB,MAAZ,GAAqB,CAA5B;AACA;;AAED,UAAIuF,GAAG,GAAW,EAAlB;;AACA,WAAK,IAAIhF,CAAC,GAAGwC,KAAb,EAAoBxC,CAAC,IAAIyC,IAAzB,EAA+BzC,CAAC,EAAhC,EAAoC;AACnC,YAAIiC,CAAC,GAAU,KAAKjB,MAAL,CAAYhB,CAAZ,CAAf;;AACA,YAAIiC,CAAC,CAACK,IAAF,KAAWzB,OAAA,CAAAc,KAAA,CAAMC,GAArB,EAA0B;AACzB;AACA;;AAEDoD,QAAAA,GAAG,IAAI/C,CAAC,CAACgD,IAAT;AACA;;AAED,aAAOD,GAAG,CAACE,QAAJ,EAAP;AACA;AA5d8B;AAAA;AAAA,qCAgeP1C,KAheO,EAgeKC,IAheL,EAgec;AAC5C,UAAI,KAAK0C,OAAL,CAAa3C,KAAb,KAAuB,KAAK2C,OAAL,CAAa1C,IAAb,CAA3B,EAA+C;AAC9C,eAAO,KAAK2C,OAAL,CAAa1E,UAAA,CAAAgE,QAAA,CAASC,EAAT,CAAYnC,KAAK,CAACJ,UAAlB,EAA8BK,IAAI,CAACL,UAAnC,CAAb,CAAP;AACA;;AAED,aAAO,EAAP;AACA;AAED;;AAxe+B;AAAA;AAAA,2BAyepB;AACV,WAAKb,QAAL;AACA,UAAM8D,SAAS,GAAW,IAA1B;;AACA,aAAO,IAAP,EAAa;AACZ,YAAItD,OAAO,GAAW,KAAKC,KAAL,CAAWqD,SAAX,CAAtB;;AACA,YAAItD,OAAO,GAAGsD,SAAd,EAAyB;AACxB;AACA;AACD;AACD,KAlf8B,CAof/B;;AApf+B;AAAA;AAAA,oCAqfPpD,CArfO,EAqfC;AAC/B,aAAOA,CAAC,YAAYxB,aAAA,CAAA6E,WAApB;AACA,KAvf8B,CAyf/B;;AAzf+B;AAAA;AAAA,4BA0ffrD,CA1fe,EA0fT;AACrB,aAAOA,CAAC,YAAYxB,aAAA,CAAA6E,WAApB;AACA;AA5f8B;AAAA;AAAA,wBAiDhB;AACd,aAAO,KAAKlE,YAAZ;AACA;AAED;AArD+B;AAAA,sBAsDfL,WAtDe,EAsDS;AACvC,WAAKK,YAAL,GAAoBL,WAApB;AACA,WAAKC,MAAL,CAAYvB,MAAZ,GAAqB,CAArB;AACA,WAAKwB,CAAL,GAAS,CAAC,CAAV;AACA,WAAKC,UAAL,GAAkB,KAAlB;AACA;AA3D8B;AAAA;AAAA,wBA8DtB;AACR,aAAO,KAAKD,CAAZ;AACA;AAhE8B;AAAA;AAAA,wBAmFvB;AACP,aAAO,KAAKD,MAAL,CAAYvB,MAAnB;AACA;AArF8B;AAAA;AAAA,wBAobjB;AACb,aAAO,KAAKsB,WAAL,CAAiBwE,UAAxB;AACA;AAtb8B;AAAA;AAAA,GAAhC;;AAKCrG,UAAA,CAAA,CADC0B,YAAA,CAAA4E,OACD,CAAA,EDsZE1E,mBAAmB,CAAC2E,SCtZtB,EDsZiC,cCtZjC,EDsZiD,KAAK,CCtZtD,CAAA;;AA4CAvG,UAAA,CAAA,CADC0B,YAAA,CAAA8E,QACD,CAAA,ED6WE5E,mBAAmB,CAAC2E,SC7WtB,ED6WiC,aC7WjC,ED6WgD,IC7WhD,CAAA;;AAaAvG,UAAA,CAAA,CADC0B,YAAA,CAAA8E,QACD,CAAA,EDmWE5E,mBAAmB,CAAC2E,SCnWtB,EDmWiC,OCnWjC,EDmW0C,ICnW1C,CAAA;;AAKAvG,UAAA,CAAA,CADC0B,YAAA,CAAA8E,QACD,CAAA,EDiWE5E,mBAAmB,CAAC2E,SCjWtB,EDiWiC,MCjWjC,EDiWyC,ICjWzC,CAAA;;AAKAvG,UAAA,CAAA,CADC0B,YAAA,CAAA8E,QACD,CAAA,ED+VE5E,mBAAmB,CAAC2E,SC/VtB,ED+ViC,SC/VjC,ED+V4C,IC/V5C,CAAA;;AAKAvG,UAAA,CAAA,CADC0B,YAAA,CAAA8E,QACD,CAAA,ED6VE5E,mBAAmB,CAAC2E,SC7VtB,ED6ViC,MC7VjC,ED6VyC,IC7VzC,CAAA;;AAMAvG,UAAA,CAAA,CADC0B,YAAA,CAAA8E,QACD,CAAA,ED0VE5E,mBAAmB,CAAC2E,SC1VtB,ED0ViC,MC1VjC,ED0VyC,IC1VzC,CAAA;;AAKAvG,UAAA,CAAA,CADC0B,YAAA,CAAA8E,QACD,CAAA,EDwVE5E,mBAAmB,CAAC2E,SCxVtB,EDwViC,SCxVjC,EDwV4C,ICxV5C,CAAA;;AAqEAvG,UAAA,CAAA,CADC0B,YAAA,CAAA8E,QACD,CAAA,EDsRE5E,mBAAmB,CAAC2E,SCtRtB,EDsRiC,KCtRjC,EDsRwC,ICtRxC,CAAA;;AAiCAvG,UAAA,CAAA,CADC0B,YAAA,CAAA8E,QACD,CAAA,EDwPE5E,mBAAmB,CAAC2E,SCxPtB,EDwPiC,ICxPjC,EDwPuC,ICxPvC,CAAA;;AAmBAvG,UAAA,CAAA,CAFC0B,YAAA,CAAA4E,OAED,EADC5E,YAAA,CAAA8E,QACD,CAAA,EDyOE5E,mBAAmB,CAAC2E,SCzOtB,EDyOiC,ICzOjC,EDyOuC,ICzOvC,CAAA;;AAmOAvG,UAAA,CAAA,CADC0B,YAAA,CAAA8E,QACD,CAAA,EDSE5E,mBAAmB,CAAC2E,SCTtB,EDSiC,YCTjC,EDS+C,ICT/C,CAAA;;AAUAvG,UAAA,CAAA,CAFC0B,YAAA,CAAA4E,OAED,EADC5E,YAAA,CAAA8E,QACD,CAAA,EDGE5E,mBAAmB,CAAC2E,SCHtB,EDGiC,SCHjC,EDG4C,ICH5C,CAAA;;AAkCAvG,UAAA,CAAA,CAFC0B,YAAA,CAAA4E,OAED,EADC5E,YAAA,CAAA8E,QACD,CAAA,ED3BE5E,mBAAmB,CAAC2E,SC2BtB,ED3BiC,kBC2BjC,ED3BqD,IC2BrD,CAAA;;AAheY3E,mBAAmB,GAAA5B,UAAA,CAAA,CAwClBgB,OAAA,CAAA,CAAA,EAAAU,YAAA,CAAA4E,OAAA,CAxCkB,CAAA,EAAnB1E,mBAAmB,CAAnB;AAAAT,OAAA,CAAAS,mBAAA,GAAAA,mBAAA","file":"BufferedTokenStream.js","sourcesContent":["\"use strict\";\n/*!\n * Copyright 2016 The ANTLR Project. All rights reserved.\n * Licensed under the BSD-3-Clause license. See LICENSE file in the project root for license information.\n */\nvar __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nvar __param = (this && this.__param) || function (paramIndex, decorator) {\n    return function (target, key) { decorator(target, key, paramIndex); }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// ConvertTo-TS run at 2016-10-04T11:26:49.6074365-07:00\nconst assert = require(\"assert\");\nconst CommonToken_1 = require(\"./CommonToken\");\nconst Interval_1 = require(\"./misc/Interval\");\nconst Lexer_1 = require(\"./Lexer\");\nconst Decorators_1 = require(\"./Decorators\");\nconst Token_1 = require(\"./Token\");\n/**\n * This implementation of {@link TokenStream} loads tokens from a\n * {@link TokenSource} on-demand, and places the tokens in a buffer to provide\n * access to any previous token by index.\n *\n * This token stream ignores the value of {@link Token#getChannel}. If your\n * parser requires the token stream filter tokens to only those on a particular\n * channel, such as {@link Token#DEFAULT_CHANNEL} or\n * {@link Token#HIDDEN_CHANNEL}, use a filtering token stream such a\n * {@link CommonTokenStream}.\n */\nlet BufferedTokenStream = class BufferedTokenStream {\n    constructor(tokenSource) {\n        /**\n         * A collection of all tokens fetched from the token source. The list is\n         * considered a complete view of the input once {@link #fetchedEOF} is set\n         * to `true`.\n         */\n        this.tokens = [];\n        /**\n         * The index into {@link #tokens} of the current token (next token to\n         * {@link #consume}). {@link #tokens}`[`{@link #p}`]` should be\n         * {@link #LT LT(1)}.\n         *\n         * This field is set to -1 when the stream is first constructed or when\n         * {@link #setTokenSource} is called, indicating that the first token has\n         * not yet been fetched from the token source. For additional information,\n         * see the documentation of {@link IntStream} for a description of\n         * Initializing Methods.\n         */\n        this.p = -1;\n        /**\n         * Indicates whether the {@link Token#EOF} token has been fetched from\n         * {@link #tokenSource} and added to {@link #tokens}. This field improves\n         * performance for the following cases:\n         *\n         * * {@link #consume}: The lookahead check in {@link #consume} to prevent\n         *   consuming the EOF symbol is optimized by checking the values of\n         *   {@link #fetchedEOF} and {@link #p} instead of calling {@link #LA}.\n         * * {@link #fetch}: The check to prevent adding multiple EOF symbols into\n         *   {@link #tokens} is trivial with this field.\n         */\n        this.fetchedEOF = false;\n        if (tokenSource == null) {\n            throw new Error(\"tokenSource cannot be null\");\n        }\n        this._tokenSource = tokenSource;\n    }\n    get tokenSource() {\n        return this._tokenSource;\n    }\n    /** Reset this token stream by setting its token source. */\n    set tokenSource(tokenSource) {\n        this._tokenSource = tokenSource;\n        this.tokens.length = 0;\n        this.p = -1;\n        this.fetchedEOF = false;\n    }\n    get index() {\n        return this.p;\n    }\n    mark() {\n        return 0;\n    }\n    release(marker) {\n        // no resources to release\n    }\n    seek(index) {\n        this.lazyInit();\n        this.p = this.adjustSeekIndex(index);\n    }\n    get size() {\n        return this.tokens.length;\n    }\n    consume() {\n        let skipEofCheck;\n        if (this.p >= 0) {\n            if (this.fetchedEOF) {\n                // the last token in tokens is EOF. skip check if p indexes any\n                // fetched token except the last.\n                skipEofCheck = this.p < this.tokens.length - 1;\n            }\n            else {\n                // no EOF token in tokens. skip check if p indexes a fetched token.\n                skipEofCheck = this.p < this.tokens.length;\n            }\n        }\n        else {\n            // not yet initialized\n            skipEofCheck = false;\n        }\n        if (!skipEofCheck && this.LA(1) === Token_1.Token.EOF) {\n            throw new Error(\"cannot consume EOF\");\n        }\n        if (this.sync(this.p + 1)) {\n            this.p = this.adjustSeekIndex(this.p + 1);\n        }\n    }\n    /** Make sure index `i` in tokens has a token.\n     *\n     * @returns `true` if a token is located at index `i`, otherwise\n     *    `false`.\n     * @see #get(int i)\n     */\n    sync(i) {\n        assert(i >= 0);\n        let n = i - this.tokens.length + 1; // how many more elements we need?\n        //System.out.println(\"sync(\"+i+\") needs \"+n);\n        if (n > 0) {\n            let fetched = this.fetch(n);\n            return fetched >= n;\n        }\n        return true;\n    }\n    /** Add `n` elements to buffer.\n     *\n     * @returns The actual number of elements added to the buffer.\n     */\n    fetch(n) {\n        if (this.fetchedEOF) {\n            return 0;\n        }\n        for (let i = 0; i < n; i++) {\n            let t = this.tokenSource.nextToken();\n            if (this.isWritableToken(t)) {\n                t.tokenIndex = this.tokens.length;\n            }\n            this.tokens.push(t);\n            if (t.type === Token_1.Token.EOF) {\n                this.fetchedEOF = true;\n                return i + 1;\n            }\n        }\n        return n;\n    }\n    get(i) {\n        if (i < 0 || i >= this.tokens.length) {\n            throw new RangeError(\"token index \" + i + \" out of range 0..\" + (this.tokens.length - 1));\n        }\n        return this.tokens[i];\n    }\n    /** Get all tokens from start..stop inclusively. */\n    getRange(start, stop) {\n        if (start < 0 || stop < 0) {\n            return [];\n        }\n        this.lazyInit();\n        let subset = new Array();\n        if (stop >= this.tokens.length) {\n            stop = this.tokens.length - 1;\n        }\n        for (let i = start; i <= stop; i++) {\n            let t = this.tokens[i];\n            if (t.type === Token_1.Token.EOF) {\n                break;\n            }\n            subset.push(t);\n        }\n        return subset;\n    }\n    LA(i) {\n        let token = this.LT(i);\n        if (!token) {\n            return Token_1.Token.INVALID_TYPE;\n        }\n        return token.type;\n    }\n    tryLB(k) {\n        if ((this.p - k) < 0) {\n            return undefined;\n        }\n        return this.tokens[this.p - k];\n    }\n    LT(k) {\n        let result = this.tryLT(k);\n        if (result === undefined) {\n            throw new RangeError(\"requested lookback index out of range\");\n        }\n        return result;\n    }\n    tryLT(k) {\n        this.lazyInit();\n        if (k === 0) {\n            throw new RangeError(\"0 is not a valid lookahead index\");\n        }\n        if (k < 0) {\n            return this.tryLB(-k);\n        }\n        let i = this.p + k - 1;\n        this.sync(i);\n        if (i >= this.tokens.length) {\n            // return EOF token\n            // EOF must be last token\n            return this.tokens[this.tokens.length - 1];\n        }\n        //\t\tif ( i>range ) range = i;\n        return this.tokens[i];\n    }\n    /**\n     * Allowed derived classes to modify the behavior of operations which change\n     * the current stream position by adjusting the target token index of a seek\n     * operation. The default implementation simply returns `i`. If an\n     * exception is thrown in this method, the current stream index should not be\n     * changed.\n     *\n     * For example, {@link CommonTokenStream} overrides this method to ensure that\n     * the seek target is always an on-channel token.\n     *\n     * @param i The target token index.\n     * @returns The adjusted target token index.\n     */\n    adjustSeekIndex(i) {\n        return i;\n    }\n    lazyInit() {\n        if (this.p === -1) {\n            this.setup();\n        }\n    }\n    setup() {\n        this.sync(0);\n        this.p = this.adjustSeekIndex(0);\n    }\n    /** Given a start and stop index, return a `List` of all tokens in\n     *  the token type `BitSet`.  Return an empty array if no tokens were found.  This\n     *  method looks at both on and off channel tokens.\n     */\n    getTokens(start, stop, types) {\n        this.lazyInit();\n        if (start === undefined) {\n            assert(stop === undefined && types === undefined);\n            return this.tokens;\n        }\n        else if (stop === undefined) {\n            stop = this.tokens.length - 1;\n        }\n        if (start < 0 || stop >= this.tokens.length || stop < 0 || start >= this.tokens.length) {\n            throw new RangeError(\"start \" + start + \" or stop \" + stop + \" not in 0..\" + (this.tokens.length - 1));\n        }\n        if (start > stop) {\n            return [];\n        }\n        if (types === undefined) {\n            return this.tokens.slice(start, stop + 1);\n        }\n        else if (typeof types === \"number\") {\n            types = new Set().add(types);\n        }\n        let typesSet = types;\n        // list = tokens[start:stop]:{T t, t.type in types}\n        let filteredTokens = this.tokens.slice(start, stop + 1);\n        filteredTokens = filteredTokens.filter((value) => typesSet.has(value.type));\n        return filteredTokens;\n    }\n    /**\n     * Given a starting index, return the index of the next token on channel.\n     * Return `i` if `tokens[i]` is on channel. Return the index of\n     * the EOF token if there are no tokens on channel between `i` and\n     * EOF.\n     */\n    nextTokenOnChannel(i, channel) {\n        this.sync(i);\n        if (i >= this.size) {\n            return this.size - 1;\n        }\n        let token = this.tokens[i];\n        while (token.channel !== channel) {\n            if (token.type === Token_1.Token.EOF) {\n                return i;\n            }\n            i++;\n            this.sync(i);\n            token = this.tokens[i];\n        }\n        return i;\n    }\n    /**\n     * Given a starting index, return the index of the previous token on\n     * channel. Return `i` if `tokens[i]` is on channel. Return -1\n     * if there are no tokens on channel between `i` and 0.\n     *\n     * If `i` specifies an index at or after the EOF token, the EOF token\n     * index is returned. This is due to the fact that the EOF token is treated\n     * as though it were on every channel.\n     */\n    previousTokenOnChannel(i, channel) {\n        this.sync(i);\n        if (i >= this.size) {\n            // the EOF token is on every channel\n            return this.size - 1;\n        }\n        while (i >= 0) {\n            let token = this.tokens[i];\n            if (token.type === Token_1.Token.EOF || token.channel === channel) {\n                return i;\n            }\n            i--;\n        }\n        return i;\n    }\n    /** Collect all tokens on specified channel to the right of\n     *  the current token up until we see a token on {@link Lexer#DEFAULT_TOKEN_CHANNEL} or\n     *  EOF. If `channel` is `-1`, find any non default channel token.\n     */\n    getHiddenTokensToRight(tokenIndex, channel = -1) {\n        this.lazyInit();\n        if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n            throw new RangeError(tokenIndex + \" not in 0..\" + (this.tokens.length - 1));\n        }\n        let nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1, Lexer_1.Lexer.DEFAULT_TOKEN_CHANNEL);\n        let to;\n        let from = tokenIndex + 1;\n        // if none onchannel to right, nextOnChannel=-1 so set to = last token\n        if (nextOnChannel === -1) {\n            to = this.size - 1;\n        }\n        else {\n            to = nextOnChannel;\n        }\n        return this.filterForChannel(from, to, channel);\n    }\n    /** Collect all tokens on specified channel to the left of\n     *  the current token up until we see a token on {@link Lexer#DEFAULT_TOKEN_CHANNEL}.\n     *  If `channel` is `-1`, find any non default channel token.\n     */\n    getHiddenTokensToLeft(tokenIndex, channel = -1) {\n        this.lazyInit();\n        if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n            throw new RangeError(tokenIndex + \" not in 0..\" + (this.tokens.length - 1));\n        }\n        if (tokenIndex === 0) {\n            // obviously no tokens can appear before the first token\n            return [];\n        }\n        let prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1, Lexer_1.Lexer.DEFAULT_TOKEN_CHANNEL);\n        if (prevOnChannel === tokenIndex - 1) {\n            return [];\n        }\n        // if none onchannel to left, prevOnChannel=-1 then from=0\n        let from = prevOnChannel + 1;\n        let to = tokenIndex - 1;\n        return this.filterForChannel(from, to, channel);\n    }\n    filterForChannel(from, to, channel) {\n        let hidden = new Array();\n        for (let i = from; i <= to; i++) {\n            let t = this.tokens[i];\n            if (channel === -1) {\n                if (t.channel !== Lexer_1.Lexer.DEFAULT_TOKEN_CHANNEL) {\n                    hidden.push(t);\n                }\n            }\n            else {\n                if (t.channel === channel) {\n                    hidden.push(t);\n                }\n            }\n        }\n        return hidden;\n    }\n    get sourceName() {\n        return this.tokenSource.sourceName;\n    }\n    getText(interval) {\n        if (interval === undefined) {\n            interval = Interval_1.Interval.of(0, this.size - 1);\n        }\n        else if (!(interval instanceof Interval_1.Interval)) {\n            // Note: the more obvious check for 'instanceof RuleContext' results in a circular dependency problem\n            interval = interval.sourceInterval;\n        }\n        let start = interval.a;\n        let stop = interval.b;\n        if (start < 0 || stop < 0) {\n            return \"\";\n        }\n        this.fill();\n        if (stop >= this.tokens.length) {\n            stop = this.tokens.length - 1;\n        }\n        let buf = \"\";\n        for (let i = start; i <= stop; i++) {\n            let t = this.tokens[i];\n            if (t.type === Token_1.Token.EOF) {\n                break;\n            }\n            buf += t.text;\n        }\n        return buf.toString();\n    }\n    getTextFromRange(start, stop) {\n        if (this.isToken(start) && this.isToken(stop)) {\n            return this.getText(Interval_1.Interval.of(start.tokenIndex, stop.tokenIndex));\n        }\n        return \"\";\n    }\n    /** Get all tokens from lexer until EOF. */\n    fill() {\n        this.lazyInit();\n        const blockSize = 1000;\n        while (true) {\n            let fetched = this.fetch(blockSize);\n            if (fetched < blockSize) {\n                return;\n            }\n        }\n    }\n    // TODO: Figure out a way to make this more flexible?\n    isWritableToken(t) {\n        return t instanceof CommonToken_1.CommonToken;\n    }\n    // TODO: Figure out a way to make this more flexible?\n    isToken(t) {\n        return t instanceof CommonToken_1.CommonToken;\n    }\n};\n__decorate([\n    Decorators_1.NotNull\n], BufferedTokenStream.prototype, \"_tokenSource\", void 0);\n__decorate([\n    Decorators_1.Override\n], BufferedTokenStream.prototype, \"tokenSource\", null);\n__decorate([\n    Decorators_1.Override\n], BufferedTokenStream.prototype, \"index\", null);\n__decorate([\n    Decorators_1.Override\n], BufferedTokenStream.prototype, \"mark\", null);\n__decorate([\n    Decorators_1.Override\n], BufferedTokenStream.prototype, \"release\", null);\n__decorate([\n    Decorators_1.Override\n], BufferedTokenStream.prototype, \"seek\", null);\n__decorate([\n    Decorators_1.Override\n], BufferedTokenStream.prototype, \"size\", null);\n__decorate([\n    Decorators_1.Override\n], BufferedTokenStream.prototype, \"consume\", null);\n__decorate([\n    Decorators_1.Override\n], BufferedTokenStream.prototype, \"get\", null);\n__decorate([\n    Decorators_1.Override\n], BufferedTokenStream.prototype, \"LA\", null);\n__decorate([\n    Decorators_1.NotNull,\n    Decorators_1.Override\n], BufferedTokenStream.prototype, \"LT\", null);\n__decorate([\n    Decorators_1.Override\n], BufferedTokenStream.prototype, \"sourceName\", null);\n__decorate([\n    Decorators_1.NotNull,\n    Decorators_1.Override\n], BufferedTokenStream.prototype, \"getText\", null);\n__decorate([\n    Decorators_1.NotNull,\n    Decorators_1.Override\n], BufferedTokenStream.prototype, \"getTextFromRange\", null);\nBufferedTokenStream = __decorate([\n    __param(0, Decorators_1.NotNull)\n], BufferedTokenStream);\nexports.BufferedTokenStream = BufferedTokenStream;\n","/*!\n * Copyright 2016 The ANTLR Project. All rights reserved.\n * Licensed under the BSD-3-Clause license. See LICENSE file in the project root for license information.\n */\n\n// ConvertTo-TS run at 2016-10-04T11:26:49.6074365-07:00\n\nimport * as assert from \"assert\";\nimport { CommonToken } from \"./CommonToken\";\nimport { Interval } from \"./misc/Interval\";\nimport { Lexer } from \"./Lexer\";\nimport { NotNull, Override } from \"./Decorators\";\nimport { RuleContext } from \"./RuleContext\";\nimport { Token } from \"./Token\";\nimport { TokenSource } from \"./TokenSource\";\nimport { TokenStream } from \"./TokenStream\";\nimport { WritableToken } from \"./WritableToken\";\n\n/**\n * This implementation of {@link TokenStream} loads tokens from a\n * {@link TokenSource} on-demand, and places the tokens in a buffer to provide\n * access to any previous token by index.\n *\n * This token stream ignores the value of {@link Token#getChannel}. If your\n * parser requires the token stream filter tokens to only those on a particular\n * channel, such as {@link Token#DEFAULT_CHANNEL} or\n * {@link Token#HIDDEN_CHANNEL}, use a filtering token stream such a\n * {@link CommonTokenStream}.\n */\nexport class BufferedTokenStream implements TokenStream {\n\t/**\n\t * The {@link TokenSource} from which tokens for this stream are fetched.\n\t */\n\t@NotNull\n\tprivate _tokenSource: TokenSource;\n\n\t/**\n\t * A collection of all tokens fetched from the token source. The list is\n\t * considered a complete view of the input once {@link #fetchedEOF} is set\n\t * to `true`.\n\t */\n\tprotected tokens: Token[] = [];\n\n\t/**\n\t * The index into {@link #tokens} of the current token (next token to\n\t * {@link #consume}). {@link #tokens}`[`{@link #p}`]` should be\n\t * {@link #LT LT(1)}.\n\t *\n\t * This field is set to -1 when the stream is first constructed or when\n\t * {@link #setTokenSource} is called, indicating that the first token has\n\t * not yet been fetched from the token source. For additional information,\n\t * see the documentation of {@link IntStream} for a description of\n\t * Initializing Methods.\n\t */\n\tprotected p: number = -1;\n\n\t/**\n\t * Indicates whether the {@link Token#EOF} token has been fetched from\n\t * {@link #tokenSource} and added to {@link #tokens}. This field improves\n\t * performance for the following cases:\n\t *\n\t * * {@link #consume}: The lookahead check in {@link #consume} to prevent\n\t *   consuming the EOF symbol is optimized by checking the values of\n\t *   {@link #fetchedEOF} and {@link #p} instead of calling {@link #LA}.\n\t * * {@link #fetch}: The check to prevent adding multiple EOF symbols into\n\t *   {@link #tokens} is trivial with this field.\n\t */\n\tprotected fetchedEOF: boolean = false;\n\n\tconstructor(@NotNull tokenSource: TokenSource) {\n\t\tif (tokenSource == null) {\n\t\t\tthrow new Error(\"tokenSource cannot be null\");\n\t\t}\n\n\t\tthis._tokenSource = tokenSource;\n\t}\n\n\t@Override\n\tget tokenSource(): TokenSource {\n\t\treturn this._tokenSource;\n\t}\n\n\t/** Reset this token stream by setting its token source. */\n\tset tokenSource(tokenSource: TokenSource) {\n\t\tthis._tokenSource = tokenSource;\n\t\tthis.tokens.length = 0;\n\t\tthis.p = -1;\n\t\tthis.fetchedEOF = false;\n\t}\n\n\t@Override\n\tget index(): number {\n\t\treturn this.p;\n\t}\n\n\t@Override\n\tpublic mark(): number {\n\t\treturn 0;\n\t}\n\n\t@Override\n\tpublic release(marker: number): void {\n\t\t// no resources to release\n\t}\n\n\t@Override\n\tpublic seek(index: number): void {\n\t\tthis.lazyInit();\n\t\tthis.p = this.adjustSeekIndex(index);\n\t}\n\n\t@Override\n\tget size(): number {\n\t\treturn this.tokens.length;\n\t}\n\n\t@Override\n\tpublic consume(): void {\n\t\tlet skipEofCheck: boolean;\n\t\tif (this.p >= 0) {\n\t\t\tif (this.fetchedEOF) {\n\t\t\t\t// the last token in tokens is EOF. skip check if p indexes any\n\t\t\t\t// fetched token except the last.\n\t\t\t\tskipEofCheck = this.p < this.tokens.length - 1;\n\t\t\t} else {\n\t\t\t\t// no EOF token in tokens. skip check if p indexes a fetched token.\n\t\t\t\tskipEofCheck = this.p < this.tokens.length;\n\t\t\t}\n\t\t} else {\n\t\t\t// not yet initialized\n\t\t\tskipEofCheck = false;\n\t\t}\n\n\t\tif (!skipEofCheck && this.LA(1) === Token.EOF) {\n\t\t\tthrow new Error(\"cannot consume EOF\");\n\t\t}\n\n\t\tif (this.sync(this.p + 1)) {\n\t\t\tthis.p = this.adjustSeekIndex(this.p + 1);\n\t\t}\n\t}\n\n\t/** Make sure index `i` in tokens has a token.\n\t *\n\t * @returns `true` if a token is located at index `i`, otherwise\n\t *    `false`.\n\t * @see #get(int i)\n\t */\n\tprotected sync(i: number): boolean {\n\t\tassert(i >= 0);\n\t\tlet n: number = i - this.tokens.length + 1; // how many more elements we need?\n\t\t//System.out.println(\"sync(\"+i+\") needs \"+n);\n\t\tif (n > 0) {\n\t\t\tlet fetched: number = this.fetch(n);\n\t\t\treturn fetched >= n;\n\t\t}\n\n\t\treturn true;\n\t}\n\n\t/** Add `n` elements to buffer.\n\t *\n\t * @returns The actual number of elements added to the buffer.\n\t */\n\tprotected fetch(n: number): number {\n\t\tif (this.fetchedEOF) {\n\t\t\treturn 0;\n\t\t}\n\n\t\tfor (let i = 0; i < n; i++) {\n\t\t\tlet t: Token = this.tokenSource.nextToken();\n\t\t\tif (this.isWritableToken(t)) {\n\t\t\t\tt.tokenIndex = this.tokens.length;\n\t\t\t}\n\n\t\t\tthis.tokens.push(t);\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tthis.fetchedEOF = true;\n\t\t\t\treturn i + 1;\n\t\t\t}\n\t\t}\n\n\t\treturn n;\n\t}\n\n\t@Override\n\tpublic get(i: number): Token {\n\t\tif (i < 0 || i >= this.tokens.length) {\n\t\t\tthrow new RangeError(\"token index \" + i + \" out of range 0..\" + (this.tokens.length - 1));\n\t\t}\n\n\t\treturn this.tokens[i];\n\t}\n\n\t/** Get all tokens from start..stop inclusively. */\n\tpublic getRange(start: number, stop: number): Token[] {\n\t\tif (start < 0 || stop < 0) {\n\t\t\treturn [];\n\t\t}\n\n\t\tthis.lazyInit();\n\t\tlet subset: Token[] = new Array<Token>();\n\t\tif (stop >= this.tokens.length) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\n\t\tfor (let i = start; i <= stop; i++) {\n\t\t\tlet t: Token = this.tokens[i];\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tsubset.push(t);\n\t\t}\n\n\t\treturn subset;\n\t}\n\n\t@Override\n\tpublic LA(i: number): number {\n\t\tlet token = this.LT(i);\n\t\tif (!token) {\n\t\t\treturn Token.INVALID_TYPE;\n\t\t}\n\n\t\treturn token.type;\n\t}\n\n\tprotected tryLB(k: number): Token | undefined {\n\t\tif ((this.p - k) < 0) {\n\t\t\treturn undefined;\n\t\t}\n\n\t\treturn this.tokens[this.p - k];\n\t}\n\n\t@NotNull\n\t@Override\n\tpublic LT(k: number): Token {\n\t\tlet result = this.tryLT(k);\n\t\tif (result === undefined) {\n\t\t\tthrow new RangeError(\"requested lookback index out of range\");\n\t\t}\n\n\t\treturn result;\n\t}\n\n\tpublic tryLT(k: number): Token | undefined {\n\t\tthis.lazyInit();\n\t\tif (k === 0) {\n\t\t\tthrow new RangeError(\"0 is not a valid lookahead index\");\n\t\t}\n\n\t\tif (k < 0) {\n\t\t\treturn this.tryLB(-k);\n\t\t}\n\n\t\tlet i: number = this.p + k - 1;\n\t\tthis.sync(i);\n\t\tif (i >= this.tokens.length) {\n\t\t\t// return EOF token\n\t\t\t// EOF must be last token\n\t\t\treturn this.tokens[this.tokens.length - 1];\n\t\t}\n\n\t\t//\t\tif ( i>range ) range = i;\n\t\treturn this.tokens[i];\n\t}\n\n\t/**\n\t * Allowed derived classes to modify the behavior of operations which change\n\t * the current stream position by adjusting the target token index of a seek\n\t * operation. The default implementation simply returns `i`. If an\n\t * exception is thrown in this method, the current stream index should not be\n\t * changed.\n\t *\n\t * For example, {@link CommonTokenStream} overrides this method to ensure that\n\t * the seek target is always an on-channel token.\n\t *\n\t * @param i The target token index.\n\t * @returns The adjusted target token index.\n\t */\n\tprotected adjustSeekIndex(i: number): number {\n\t\treturn i;\n\t}\n\n\tprotected lazyInit(): void {\n\t\tif (this.p === -1) {\n\t\t\tthis.setup();\n\t\t}\n\t}\n\n\tprotected setup(): void {\n\t\tthis.sync(0);\n\t\tthis.p = this.adjustSeekIndex(0);\n\t}\n\n\tpublic getTokens(): Token[];\n\n\tpublic getTokens(start: number, stop: number): Token[];\n\n\tpublic getTokens(start: number, stop: number, types: Set<number>): Token[];\n\n\tpublic getTokens(start: number, stop: number, ttype: number): Token[];\n\n\t/** Given a start and stop index, return a `List` of all tokens in\n\t *  the token type `BitSet`.  Return an empty array if no tokens were found.  This\n\t *  method looks at both on and off channel tokens.\n\t */\n\tpublic getTokens(start?: number, stop?: number, types?: Set<number> | number): Token[] {\n\t\tthis.lazyInit();\n\n\t\tif (start === undefined) {\n\t\t\tassert(stop === undefined && types === undefined);\n\t\t\treturn this.tokens;\n\t\t} else if (stop === undefined) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\n\t\tif (start < 0 || stop >= this.tokens.length || stop < 0 || start >= this.tokens.length) {\n\t\t\tthrow new RangeError(\"start \" + start + \" or stop \" + stop + \" not in 0..\" + (this.tokens.length - 1));\n\t\t}\n\n\t\tif (start > stop) {\n\t\t\treturn [];\n\t\t}\n\n\t\tif (types === undefined) {\n\t\t\treturn this.tokens.slice(start, stop + 1);\n\t\t} else if (typeof types === \"number\") {\n\t\t\ttypes = new Set<number>().add(types);\n\t\t}\n\n\t\tlet typesSet = types;\n\n\t\t// list = tokens[start:stop]:{T t, t.type in types}\n\t\tlet filteredTokens: Token[] = this.tokens.slice(start, stop + 1);\n\t\tfilteredTokens = filteredTokens.filter((value) => typesSet.has(value.type));\n\n\t\treturn filteredTokens;\n\t}\n\n\t/**\n\t * Given a starting index, return the index of the next token on channel.\n\t * Return `i` if `tokens[i]` is on channel. Return the index of\n\t * the EOF token if there are no tokens on channel between `i` and\n\t * EOF.\n\t */\n\tprotected nextTokenOnChannel(i: number, channel: number): number {\n\t\tthis.sync(i);\n\t\tif (i >= this.size) {\n\t\t\treturn this.size - 1;\n\t\t}\n\n\t\tlet token: Token = this.tokens[i];\n\t\twhile (token.channel !== channel) {\n\t\t\tif (token.type === Token.EOF) {\n\t\t\t\treturn i;\n\t\t\t}\n\n\t\t\ti++;\n\t\t\tthis.sync(i);\n\t\t\ttoken = this.tokens[i];\n\t\t}\n\n\t\treturn i;\n\t}\n\n\t/**\n\t * Given a starting index, return the index of the previous token on\n\t * channel. Return `i` if `tokens[i]` is on channel. Return -1\n\t * if there are no tokens on channel between `i` and 0.\n\t *\n\t * If `i` specifies an index at or after the EOF token, the EOF token\n\t * index is returned. This is due to the fact that the EOF token is treated\n\t * as though it were on every channel.\n\t */\n\tprotected previousTokenOnChannel(i: number, channel: number): number {\n\t\tthis.sync(i);\n\t\tif (i >= this.size) {\n\t\t\t// the EOF token is on every channel\n\t\t\treturn this.size - 1;\n\t\t}\n\n\t\twhile (i >= 0) {\n\t\t\tlet token: Token = this.tokens[i];\n\t\t\tif (token.type === Token.EOF || token.channel === channel) {\n\t\t\t\treturn i;\n\t\t\t}\n\n\t\t\ti--;\n\t\t}\n\n\t\treturn i;\n\t}\n\n\t/** Collect all tokens on specified channel to the right of\n\t *  the current token up until we see a token on {@link Lexer#DEFAULT_TOKEN_CHANNEL} or\n\t *  EOF. If `channel` is `-1`, find any non default channel token.\n\t */\n\tpublic getHiddenTokensToRight(tokenIndex: number, channel: number = -1): Token[] {\n\t\tthis.lazyInit();\n\t\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\t\tthrow new RangeError(tokenIndex + \" not in 0..\" + (this.tokens.length - 1));\n\t\t}\n\n\t\tlet nextOnChannel: number = this.nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\t\tlet to: number;\n\t\tlet from: number = tokenIndex + 1;\n\t\t// if none onchannel to right, nextOnChannel=-1 so set to = last token\n\t\tif (nextOnChannel === -1) {\n\t\t\tto = this.size - 1;\n\t\t} else {\n\t\t\tto = nextOnChannel;\n\t\t}\n\n\t\treturn this.filterForChannel(from, to, channel);\n\t}\n\n\t/** Collect all tokens on specified channel to the left of\n\t *  the current token up until we see a token on {@link Lexer#DEFAULT_TOKEN_CHANNEL}.\n\t *  If `channel` is `-1`, find any non default channel token.\n\t */\n\tpublic getHiddenTokensToLeft(tokenIndex: number, channel: number = -1): Token[] {\n\t\tthis.lazyInit();\n\t\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\t\tthrow new RangeError(tokenIndex + \" not in 0..\" + (this.tokens.length - 1));\n\t\t}\n\n\t\tif (tokenIndex === 0) {\n\t\t\t// obviously no tokens can appear before the first token\n\t\t\treturn [];\n\t\t}\n\n\t\tlet prevOnChannel: number = this.previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\t\tif (prevOnChannel === tokenIndex - 1) {\n\t\t\treturn [];\n\t\t}\n\n\t\t// if none onchannel to left, prevOnChannel=-1 then from=0\n\t\tlet from: number = prevOnChannel + 1;\n\t\tlet to: number = tokenIndex - 1;\n\n\t\treturn this.filterForChannel(from, to, channel);\n\t}\n\n\tprotected filterForChannel(from: number, to: number, channel: number): Token[] {\n\t\tlet hidden: Token[] = new Array<Token>();\n\t\tfor (let i = from; i <= to; i++) {\n\t\t\tlet t: Token = this.tokens[i];\n\t\t\tif (channel === -1) {\n\t\t\t\tif (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {\n\t\t\t\t\thidden.push(t);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (t.channel === channel) {\n\t\t\t\t\thidden.push(t);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn hidden;\n\t}\n\n\t@Override\n\tget sourceName(): string {\n\t\treturn this.tokenSource.sourceName;\n\t}\n\n\t/** Get the text of all tokens in this buffer. */\n\tpublic getText(): string;\n\tpublic getText(interval: Interval): string;\n\tpublic getText(context: RuleContext): string;\n\t@NotNull\n\t@Override\n\tpublic getText(interval?: Interval | RuleContext): string {\n\t\tif (interval === undefined) {\n\t\t\tinterval = Interval.of(0, this.size - 1);\n\t\t} else if (!(interval instanceof Interval)) {\n\t\t\t// Note: the more obvious check for 'instanceof RuleContext' results in a circular dependency problem\n\t\t\tinterval = interval.sourceInterval;\n\t\t}\n\n\t\tlet start: number = interval.a;\n\t\tlet stop: number = interval.b;\n\t\tif (start < 0 || stop < 0) {\n\t\t\treturn \"\";\n\t\t}\n\n\t\tthis.fill();\n\t\tif (stop >= this.tokens.length) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\n\t\tlet buf: string = \"\";\n\t\tfor (let i = start; i <= stop; i++) {\n\t\t\tlet t: Token = this.tokens[i];\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tbuf += t.text;\n\t\t}\n\n\t\treturn buf.toString();\n\t}\n\n\t@NotNull\n\t@Override\n\tpublic getTextFromRange(start: any, stop: any): string {\n\t\tif (this.isToken(start) && this.isToken(stop)) {\n\t\t\treturn this.getText(Interval.of(start.tokenIndex, stop.tokenIndex));\n\t\t}\n\n\t\treturn \"\";\n\t}\n\n\t/** Get all tokens from lexer until EOF. */\n\tpublic fill(): void {\n\t\tthis.lazyInit();\n\t\tconst blockSize: number = 1000;\n\t\twhile (true) {\n\t\t\tlet fetched: number = this.fetch(blockSize);\n\t\t\tif (fetched < blockSize) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n\n\t// TODO: Figure out a way to make this more flexible?\n\tprivate isWritableToken(t: Token): t is WritableToken {\n\t\treturn t instanceof CommonToken;\n\t}\n\n\t// TODO: Figure out a way to make this more flexible?\n\tprivate isToken(t: any): t is Token {\n\t\treturn t instanceof CommonToken;\n\t}\n}\n"]}