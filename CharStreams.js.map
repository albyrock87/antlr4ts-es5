{"version":3,"sources":["CharStreams.js","../src/CharStreams.ts"],"names":["Object","defineProperty","exports","value","CodePointBuffer_1","require","CodePointCharStream_1","IntStream_1","CharStreams","fromString","s","sourceName","undefined","length","IntStream","UNKNOWN_SOURCE_NAME","codePointBufferBuilder","CodePointBuffer","builder","cb","Uint16Array","i","charCodeAt","append","CodePointCharStream","fromBuffer","build"],"mappings":"AAAA;ACAA;;;;;ADKAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;;ACAA,IAAAC,iBAAA,GAAAC,OAAA,CAAA,mBAAA,CAAA;;AACA,IAAAC,qBAAA,GAAAD,OAAA,CAAA,uBAAA,CAAA;;AACA,IAAAE,WAAA,GAAAF,OAAA,CAAA,aAAA,CAAA,C,CAEA;;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAsCA,IAAiBG,WAAjB;;AAAA,CAAA,UAAiBA,WAAjB,EAA4B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAuLA,WAAAC,UAAA,CAA2BC,CAA3B,EAAsCC,UAAtC,EAAyD;AACxD,QAAIA,UAAU,KAAKC,SAAf,IAA4BD,UAAU,CAACE,MAAX,KAAsB,CAAtD,EAAyD;AACxDF,MAAAA,UAAU,GAAGJ,WAAA,CAAAO,SAAA,CAAUC,mBAAvB;AACA,KAHuD,CAKxD;AACA;;;AACA,QAAIC,sBAAsB,GAA4BZ,iBAAA,CAAAa,eAAA,CAAgBC,OAAhB,CAAwBR,CAAC,CAACG,MAA1B,CAAtD,CAPwD,CASxD;AACA;;AACA,QAAIM,EAAE,GAAgB,IAAIC,WAAJ,CAAgBV,CAAC,CAACG,MAAlB,CAAtB;;AACA,SAAK,IAAIQ,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGX,CAAC,CAACG,MAAtB,EAA8BQ,CAAC,EAA/B,EAAmC;AAClCF,MAAAA,EAAE,CAACE,CAAD,CAAF,GAAQX,CAAC,CAACY,UAAF,CAAaD,CAAb,CAAR;AACA;;AAEDL,IAAAA,sBAAsB,CAACO,MAAvB,CAA8BJ,EAA9B;AACA,WAAOb,qBAAA,CAAAkB,mBAAA,CAAoBC,UAApB,CAA+BT,sBAAsB,CAACU,KAAvB,EAA/B,EAA+Df,UAA/D,CAAP;AACA;;AAlBeH,EAAAA,WAAA,CAAAC,UAAA,GAAUA,UAAV,CAnMW,CAuN3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CA/QD,EAAiBD,WAAW,GAAXN,OAAA,CAAAM,WAAA,KAAAN,OAAA,CAAAM,WAAA,GAAW,EAAX,CAAjB","file":"CharStreams.js","sourcesContent":["\"use strict\";\n/*!\n * Copyright 2016 The ANTLR Project. All rights reserved.\n * Licensed under the BSD-3-Clause license. See LICENSE file in the project root for license information.\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst CodePointBuffer_1 = require(\"./CodePointBuffer\");\nconst CodePointCharStream_1 = require(\"./CodePointCharStream\");\nconst IntStream_1 = require(\"./IntStream\");\n// const DEFAULT_BUFFER_SIZE: number = 4096;\n/** This class represents the primary interface for creating {@link CharStream}s\n *  from a variety of sources as of 4.7.  The motivation was to support\n *  Unicode code points > U+FFFF.  {@link ANTLRInputStream} and\n *  {@link ANTLRFileStream} are now deprecated in favor of the streams created\n *  by this interface.\n *\n *  DEPRECATED: {@code new ANTLRFileStream(\"myinputfile\")}\n *  NEW:        {@code CharStreams.fromFileName(\"myinputfile\")}\n *\n *  WARNING: If you use both the deprecated and the new streams, you will see\n *  a nontrivial performance degradation. This speed hit is because the\n *  {@link Lexer}'s internal code goes from a monomorphic to megamorphic\n *  dynamic dispatch to get characters from the input stream. Java's\n *  on-the-fly compiler (JIT) is unable to perform the same optimizations\n *  so stick with either the old or the new streams, if performance is\n *  a primary concern. See the extreme debugging and spelunking\n *  needed to identify this issue in our timing rig:\n *\n *      https://github.com/antlr/antlr4/pull/1781\n *\n *  The ANTLR character streams still buffer all the input when you create\n *  the stream, as they have done for ~20 years. If you need unbuffered\n *  access, please note that it becomes challenging to create\n *  parse trees. The parse tree has to point to tokens which will either\n *  point into a stale location in an unbuffered stream or you have to copy\n *  the characters out of the buffer into the token. That defeats the purpose\n *  of unbuffered input. Per the ANTLR book, unbuffered streams are primarily\n *  useful for processing infinite streams *during the parse.*\n *\n *  The new streams also use 8-bit buffers when possible so this new\n *  interface supports character streams that use half as much memory\n *  as the old {@link ANTLRFileStream}, which assumed 16-bit characters.\n *\n *  A big shout out to Ben Hamilton (github bhamiltoncx) for his superhuman\n *  efforts across all targets to get true Unicode 3.1 support for U+10FFFF.\n *\n *  @since 4.7\n */\nvar CharStreams;\n(function (CharStreams) {\n    // /**\n    //  * Creates a {@link CharStream} given a path to a UTF-8\n    //  * encoded file on disk.\n    //  *\n    //  * Reads the entire contents of the file into the result before returning.\n    //  */\n    // export function fromFile(file: File): CharStream;\n    // export function fromFile(file: File, charset: Charset): CharStream;\n    // export function fromFile(file: File, charset?: Charset): CharStream {\n    // \tif (charset === undefined) {\n    // \t\tcharset = Charset.forName(\"UTF-8\");\n    // \t}\n    function fromString(s, sourceName) {\n        if (sourceName === undefined || sourceName.length === 0) {\n            sourceName = IntStream_1.IntStream.UNKNOWN_SOURCE_NAME;\n        }\n        // Initial guess assumes no code points > U+FFFF: one code\n        // point for each code unit in the string\n        let codePointBufferBuilder = CodePointBuffer_1.CodePointBuffer.builder(s.length);\n        // TODO: CharBuffer.wrap(String) rightfully returns a read-only buffer\n        // which doesn't expose its array, so we make a copy.\n        let cb = new Uint16Array(s.length);\n        for (let i = 0; i < s.length; i++) {\n            cb[i] = s.charCodeAt(i);\n        }\n        codePointBufferBuilder.append(cb);\n        return CodePointCharStream_1.CodePointCharStream.fromBuffer(codePointBufferBuilder.build(), sourceName);\n    }\n    CharStreams.fromString = fromString;\n    // export function bufferFromChannel(\n    // \tchannel: ReadableByteChannel,\n    // \tcharset: Charset,\n    // \tbufferSize: number,\n    // \tdecodingErrorAction: CodingErrorAction,\n    // \tinputSize: number): CodePointBuffer {\n    // \ttry {\n    // \t\tlet utf8BytesIn: Uint8Array = new Uint8Array(bufferSize);\n    // \t\tlet utf16CodeUnitsOut: Uint16Array = new Uint16Array(bufferSize);\n    // \t\tif (inputSize === -1) {\n    // \t\t\tinputSize = bufferSize;\n    // \t\t} else if (inputSize > Integer.MAX_VALUE) {\n    // \t\t\t// ByteBuffer et al don't support long sizes\n    // \t\t\tthrow new RangeError(`inputSize ${inputSize} larger than max ${Integer.MAX_VALUE}`);\n    // \t\t}\n    // \t\tlet codePointBufferBuilder: CodePointBuffer.Builder = CodePointBuffer.builder(inputSize);\n    // \t\tlet decoder: CharsetDecoder = charset\n    // \t\t\t\t.newDecoder()\n    // \t\t\t\t.onMalformedInput(decodingErrorAction)\n    // \t\t\t\t.onUnmappableCharacter(decodingErrorAction);\n    // \t\tlet endOfInput: boolean = false;\n    // \t\twhile (!endOfInput) {\n    // \t\t\tlet bytesRead: number = channel.read(utf8BytesIn);\n    // \t\t\tendOfInput = (bytesRead === -1);\n    // \t\t\tutf8BytesIn.flip();\n    // \t\t\tlet result: CoderResult = decoder.decode(\n    // \t\t\t\tutf8BytesIn,\n    // \t\t\t\tutf16CodeUnitsOut,\n    // \t\t\t\tendOfInput);\n    // \t\t\tif (result.isError() && decodingErrorAction === CodingErrorAction.REPORT) {\n    // \t\t\t\tresult.throwException();\n    // \t\t\t}\n    // \t\t\tutf16CodeUnitsOut.flip();\n    // \t\t\tcodePointBufferBuilder.append(utf16CodeUnitsOut);\n    // \t\t\tutf8BytesIn.compact();\n    // \t\t\tutf16CodeUnitsOut.compact();\n    // \t\t}\n    // \t\t// Handle any bytes at the end of the file which need to\n    // \t\t// be represented as errors or substitution characters.\n    // \t\tlet flushResult: CoderResult = decoder.flush(utf16CodeUnitsOut);\n    // \t\tif (flushResult.isError() && decodingErrorAction === CodingErrorAction.REPORT) {\n    // \t\t\tflushResult.throwException();\n    // \t\t}\n    // \t\tutf16CodeUnitsOut.flip();\n    // \t\tcodePointBufferBuilder.append(utf16CodeUnitsOut);\n    // \t\treturn codePointBufferBuilder.build();\n    // \t}\n    // \tfinally {\n    // \t\tchannel.close();\n    // \t}\n    // }\n})(CharStreams = exports.CharStreams || (exports.CharStreams = {}));\n","/*!\n * Copyright 2016 The ANTLR Project. All rights reserved.\n * Licensed under the BSD-3-Clause license. See LICENSE file in the project root for license information.\n */\n\nimport { CodePointBuffer } from \"./CodePointBuffer\";\nimport { CodePointCharStream } from \"./CodePointCharStream\";\nimport { IntStream } from \"./IntStream\";\n\n// const DEFAULT_BUFFER_SIZE: number = 4096;\n\n/** This class represents the primary interface for creating {@link CharStream}s\n *  from a variety of sources as of 4.7.  The motivation was to support\n *  Unicode code points > U+FFFF.  {@link ANTLRInputStream} and\n *  {@link ANTLRFileStream} are now deprecated in favor of the streams created\n *  by this interface.\n *\n *  DEPRECATED: {@code new ANTLRFileStream(\"myinputfile\")}\n *  NEW:        {@code CharStreams.fromFileName(\"myinputfile\")}\n *\n *  WARNING: If you use both the deprecated and the new streams, you will see\n *  a nontrivial performance degradation. This speed hit is because the\n *  {@link Lexer}'s internal code goes from a monomorphic to megamorphic\n *  dynamic dispatch to get characters from the input stream. Java's\n *  on-the-fly compiler (JIT) is unable to perform the same optimizations\n *  so stick with either the old or the new streams, if performance is\n *  a primary concern. See the extreme debugging and spelunking\n *  needed to identify this issue in our timing rig:\n *\n *      https://github.com/antlr/antlr4/pull/1781\n *\n *  The ANTLR character streams still buffer all the input when you create\n *  the stream, as they have done for ~20 years. If you need unbuffered\n *  access, please note that it becomes challenging to create\n *  parse trees. The parse tree has to point to tokens which will either\n *  point into a stale location in an unbuffered stream or you have to copy\n *  the characters out of the buffer into the token. That defeats the purpose\n *  of unbuffered input. Per the ANTLR book, unbuffered streams are primarily\n *  useful for processing infinite streams *during the parse.*\n *\n *  The new streams also use 8-bit buffers when possible so this new\n *  interface supports character streams that use half as much memory\n *  as the old {@link ANTLRFileStream}, which assumed 16-bit characters.\n *\n *  A big shout out to Ben Hamilton (github bhamiltoncx) for his superhuman\n *  efforts across all targets to get true Unicode 3.1 support for U+10FFFF.\n *\n *  @since 4.7\n */\nexport namespace CharStreams {\n\t// /**\n\t//  * Creates a {@link CharStream} given a path to a UTF-8\n\t//  * encoded file on disk.\n\t//  *\n\t//  * Reads the entire contents of the file into the result before returning.\n\t//  */\n\t// export function fromFile(file: File): CharStream;\n\t// export function fromFile(file: File, charset: Charset): CharStream;\n\t// export function fromFile(file: File, charset?: Charset): CharStream {\n\t// \tif (charset === undefined) {\n\t// \t\tcharset = Charset.forName(\"UTF-8\");\n\t// \t}\n\n\t// \tlet size: number = file.length();\n\t// \treturn fromStream(new FileInputStream(file), charset, file.toString(), size);\n\t// }\n\n\t// /**\n\t//  * Creates a {@link CharStream} given a string containing a\n\t//  * path to a UTF-8 file on disk.\n\t//  *\n\t//  * Reads the entire contents of the file into the result before returning.\n\t//  */\n\t// export function fromFileName(fileName: string): CharStream;\n\n\t// /**\n\t//  * Creates a {@link CharStream} given a string containing a\n\t//  * path to a file on disk and the charset of the bytes\n\t//  * contained in the file.\n\t//  *\n\t//  * Reads the entire contents of the file into the result before returning.\n\t//  */\n\t// export function fromFileName(fileName: string, charset: Charset): CharStream;\n\t// export function fromFileName(fileName: string, charset?: Charset): CharStream {\n\t// \tif (charset === undefined) {\n\t// \t\tcharset = Charset.forName(\"UTF-8\");\n\t// \t}\n\n\t// \treturn fromFile(new File(fileName), charset);\n\t// }\n\n\t// /**\n\t//  * Creates a {@link CharStream} given an opened {@link InputStream}\n\t//  * containing UTF-8 bytes.\n\t//  *\n\t//  * Reads the entire contents of the {@code InputStream} into\n\t//  * the result before returning, then closes the {@code InputStream}.\n\t//  */\n\t// export function fromStream(is: InputStream): CharStream;\n\n\t// /**\n\t//  * Creates a {@link CharStream} given an opened {@link InputStream} and the\n\t//  * charset of the bytes contained in the stream.\n\t//  *\n\t//  * Reads the entire contents of the {@code InputStream} into\n\t//  * the result before returning, then closes the {@code InputStream}.\n\t//  */\n\t// export function fromStream(is: InputStream, charset: Charset): CharStream;\n\n\t// export function fromStream(is: InputStream, charset: Charset, sourceName: string, inputSize: number): CharStream;\n\t// export function fromStream(is: InputStream, charset?: Charset, sourceName?: string, inputSize?: number): CharStream {\n\t// \tif (charset === undefined) {\n\t// \t\tcharset = Charset.forName(\"UTF-8\");\n\t// \t}\n\n\t// \tif (sourceName === undefined) {\n\t// \t\tsourceName = IntStream.UNKNOWN_SOURCE_NAME;\n\t// \t}\n\n\t// \tif (inputSize === undefined) {\n\t// \t\tinputSize = -1;\n\t// \t}\n\n\t// \treturn fromChannel(\n\t// \t\tChannels.newChannel(is),\n\t// \t\tcharset,\n\t// \t\tDEFAULT_BUFFER_SIZE,\n\t// \t\tCodingErrorAction.REPLACE,\n\t// \t\tsourceName,\n\t// \t\tinputSize);\n\t// }\n\n\t// /**\n\t//  * Creates a {@link CharStream} given an opened {@link ReadableByteChannel}\n\t//  * containing UTF-8 bytes.\n\t//  *\n\t//  * Reads the entire contents of the {@code channel} into\n\t//  * the result before returning, then closes the {@code channel}.\n\t//  */\n\t// export function fromChannel(channel: ReadableByteChannel): CharStream;\n\n\t// /**\n\t//  * Creates a {@link CharStream} given an opened {@link ReadableByteChannel} and the\n\t//  * charset of the bytes contained in the channel.\n\t//  *\n\t//  * Reads the entire contents of the {@code channel} into\n\t//  * the result before returning, then closes the {@code channel}.\n\t//  */\n\t// export function fromChannel(channel: ReadableByteChannel, charset: Charset): CharStream;\n\n\t// /**\n\t//  * Creates a {@link CharStream} given an opened {@link ReadableByteChannel}\n\t//  * containing UTF-8 bytes.\n\t//  *\n\t//  * Reads the entire contents of the {@code channel} into\n\t//  * the result before returning, then closes the {@code channel}.\n\t//  */\n\t// export function fromChannel(\n\t// \tchannel: ReadableByteChannel,\n\t// \tcharset: Charset,\n\t// \tbufferSize: number,\n\t// \tdecodingErrorAction: CodingErrorAction,\n\t// \tsourceName: string): CodePointCharStream;\n\n\t// export function fromChannel(\n\t// \tchannel: ReadableByteChannel,\n\t// \tcharset: Charset,\n\t// \tbufferSize: number,\n\t// \tdecodingErrorAction: CodingErrorAction,\n\t// \tsourceName: string,\n\t// \tinputSize: number): CodePointCharStream;\n\t// export function fromChannel(\n\t// \tchannel: ReadableByteChannel,\n\t// \tcharset?: Charset,\n\t// \tbufferSize?: number,\n\t// \tdecodingErrorAction?: CodingErrorAction,\n\t// \tsourceName?: string,\n\t// \tinputSize?: number): CodePointCharStream\n\t// {\n\t// \tif (charset === undefined) {\n\t// \t\tcharset = Charset.forName(\"UTF-8\");\n\t// \t}\n\n\t// \tif (bufferSize === undefined) {\n\t// \t\tbufferSize = DEFAULT_BUFFER_SIZE;\n\t// \t}\n\n\t// \tif (decodingErrorAction === undefined) {\n\t// \t\tdecodingErrorAction = CodingErrorAction.REPLACE;\n\t// \t}\n\n\t// \tif (sourceName === undefined || sourceName.length === 0) {\n\t// \t\tsourceName = IntStream.UNKNOWN_SOURCE_NAME;\n\t// \t}\n\n\t// \tif (inputSize === undefined) {\n\t// \t\tinputSize = -1;\n\t// \t}\n\n\t// \tlet codePointBuffer: CodePointBuffer = bufferFromChannel(channel, charset, bufferSize, decodingErrorAction, inputSize);\n\t// \treturn CodePointCharStream.fromBuffer(codePointBuffer, sourceName);\n\t// }\n\n\t// /**\n\t//  * Creates a {@link CharStream} given a {@link Reader}. Closes\n\t//  * the reader before returning.\n\t//  */\n\t// export function fromReader(r: Reader): CodePointCharStream;\n\n\t// /**\n\t//  * Creates a {@link CharStream} given a {@link Reader} and its\n\t//  * source name. Closes the reader before returning.\n\t//  */\n\t// export function fromReader(r: Reader, sourceName: string): CodePointCharStream;\n\t// export function fromReader(r: Reader, sourceName?: string): CodePointCharStream {\n\t// \tif (sourceName === undefined) {\n\t// \t\tsourceName = IntStream.UNKNOWN_SOURCE_NAME;\n\t// \t}\n\n\t// \ttry {\n\t// \t\tlet codePointBufferBuilder: CodePointBuffer.Builder = CodePointBuffer.builder(DEFAULT_BUFFER_SIZE);\n\t// \t\tlet charBuffer: CharBuffer = CharBuffer.allocate(DEFAULT_BUFFER_SIZE);\n\t// \t\twhile ((r.read(charBuffer)) !== -1) {\n\t// \t\t\tcharBuffer.flip();\n\t// \t\t\tcodePointBufferBuilder.append(charBuffer);\n\t// \t\t\tcharBuffer.compact();\n\t// \t\t}\n\n\t// \t\treturn CodePointCharStream.fromBuffer(codePointBufferBuilder.build(), sourceName);\n\t// \t} finally {\n\t// \t\tr.close();\n\t// \t}\n\t// }\n\n\t/**\n\t * Creates a {@link CharStream} given a {@link String}.\n\t */\n\texport function fromString(s: string): CodePointCharStream;\n\n\t/**\n\t * Creates a {@link CharStream} given a {@link String} and the {@code sourceName}\n\t * from which it came.\n\t */\n\texport function fromString(s: string, sourceName: string): CodePointCharStream;\n\texport function fromString(s: string, sourceName?: string): CodePointCharStream {\n\t\tif (sourceName === undefined || sourceName.length === 0) {\n\t\t\tsourceName = IntStream.UNKNOWN_SOURCE_NAME;\n\t\t}\n\n\t\t// Initial guess assumes no code points > U+FFFF: one code\n\t\t// point for each code unit in the string\n\t\tlet codePointBufferBuilder: CodePointBuffer.Builder = CodePointBuffer.builder(s.length);\n\n\t\t// TODO: CharBuffer.wrap(String) rightfully returns a read-only buffer\n\t\t// which doesn't expose its array, so we make a copy.\n\t\tlet cb: Uint16Array = new Uint16Array(s.length);\n\t\tfor (let i = 0; i < s.length; i++) {\n\t\t\tcb[i] = s.charCodeAt(i);\n\t\t}\n\n\t\tcodePointBufferBuilder.append(cb);\n\t\treturn CodePointCharStream.fromBuffer(codePointBufferBuilder.build(), sourceName);\n\t}\n\n\t// export function bufferFromChannel(\n\t// \tchannel: ReadableByteChannel,\n\t// \tcharset: Charset,\n\t// \tbufferSize: number,\n\t// \tdecodingErrorAction: CodingErrorAction,\n\t// \tinputSize: number): CodePointBuffer {\n\t// \ttry {\n\t// \t\tlet utf8BytesIn: Uint8Array = new Uint8Array(bufferSize);\n\t// \t\tlet utf16CodeUnitsOut: Uint16Array = new Uint16Array(bufferSize);\n\t// \t\tif (inputSize === -1) {\n\t// \t\t\tinputSize = bufferSize;\n\t// \t\t} else if (inputSize > Integer.MAX_VALUE) {\n\t// \t\t\t// ByteBuffer et al don't support long sizes\n\t// \t\t\tthrow new RangeError(`inputSize ${inputSize} larger than max ${Integer.MAX_VALUE}`);\n\t// \t\t}\n\n\t// \t\tlet codePointBufferBuilder: CodePointBuffer.Builder = CodePointBuffer.builder(inputSize);\n\t// \t\tlet decoder: CharsetDecoder = charset\n\t// \t\t\t\t.newDecoder()\n\t// \t\t\t\t.onMalformedInput(decodingErrorAction)\n\t// \t\t\t\t.onUnmappableCharacter(decodingErrorAction);\n\n\t// \t\tlet endOfInput: boolean = false;\n\t// \t\twhile (!endOfInput) {\n\t// \t\t\tlet bytesRead: number = channel.read(utf8BytesIn);\n\t// \t\t\tendOfInput = (bytesRead === -1);\n\t// \t\t\tutf8BytesIn.flip();\n\t// \t\t\tlet result: CoderResult = decoder.decode(\n\t// \t\t\t\tutf8BytesIn,\n\t// \t\t\t\tutf16CodeUnitsOut,\n\t// \t\t\t\tendOfInput);\n\t// \t\t\tif (result.isError() && decodingErrorAction === CodingErrorAction.REPORT) {\n\t// \t\t\t\tresult.throwException();\n\t// \t\t\t}\n\n\t// \t\t\tutf16CodeUnitsOut.flip();\n\t// \t\t\tcodePointBufferBuilder.append(utf16CodeUnitsOut);\n\t// \t\t\tutf8BytesIn.compact();\n\t// \t\t\tutf16CodeUnitsOut.compact();\n\t// \t\t}\n\t// \t\t// Handle any bytes at the end of the file which need to\n\t// \t\t// be represented as errors or substitution characters.\n\t// \t\tlet flushResult: CoderResult = decoder.flush(utf16CodeUnitsOut);\n\t// \t\tif (flushResult.isError() && decodingErrorAction === CodingErrorAction.REPORT) {\n\t// \t\t\tflushResult.throwException();\n\t// \t\t}\n\n\t// \t\tutf16CodeUnitsOut.flip();\n\t// \t\tcodePointBufferBuilder.append(utf16CodeUnitsOut);\n\n\t// \t\treturn codePointBufferBuilder.build();\n\t// \t}\n\t// \tfinally {\n\t// \t\tchannel.close();\n\t// \t}\n\t// }\n}\n"]}